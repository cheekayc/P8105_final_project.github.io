<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Final Report</title>

<script src="site_libs/header-attrs-2.16/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/sandstone.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="https://github.com/cheekayc/P8105_final_project.github.io">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a>
    <span class="fa fa-brands fa-youtube"></span>
     
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="statistical_analyses.html">Statistical Analyses</a>
</li>
<li>
  <a href="plot.html">Exploratory Analyses</a>
</li>
<li>
  <a href="forecast.html">Forecast Analyses</a>
</li>
<li>
  <a href="final_report.html">Final Report</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Final Report</h1>

</div>


<pre class="r"><code>knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE,
  fig.width = 18,
  fig.height = 8,
  out.width = &quot;90%&quot;,
  set.seed(8))

library(tidyverse)
library(forecast)
library(astsa)
library(MLmetrics)
library(lubridate)
library(plotly)
library(mgcv)
library(moments)
library(modelr)</code></pre>
<div id="project-title" class="section level2">
<h2>Project title</h2>
A French Bakery’s Daily Sales in 2021-2022
<p>
 
</p >
</div>
<div id="data-collection-and-cleaning" class="section level2">
<h2>Data collection and cleaning</h2>
<p><a
href="https://www.kaggle.com/datasets/matthieugimbert/french-bakery-daily-sales">kaggle</a></p>
<a
href="https://www.france-hotel-guide.com/en/blog/cost-baguette-paris/">price
comparison</a>
<p>
 
</p >
<p>We used updated version dataset of a French bakery from 2021-01-01 to
2022-09-30. The dataset provides the daily transaction details of
customers. Since the dataset is still updating, we used downloaded
version on 2022-12-03.</p>
<p>The dataset includes:</p>
<p><code>date</code>: date order</p>
<p><code>time</code>: time order</p>
<p><code>ticket number</code>: identifier for every single
transaction</p>
<p><code>article</code>: name of the product sold (in French)</p>
<p><code>quantity</code>: quantity sold</p>
<p><code>unit_price</code>: price per product (in Euro)</p>
<p><code>objective</code>: forecast the sales in order to ease the
production planning</p>
<p>It contains 7 variables and 234000 observations.</p>
<p>
 
</p >
Firstly, we used <code>read_csv()</code> to import the dataset
“Bakery_sales.csv”, and applied <code>janitor::clean_names()</code> to
change the variables’ names into lower cases. Next, we tidied dataset by
applying <code>mutate()</code> to remove the euro sign “€”, change “,”
to “.”, convert <code>unit_price</code> to numeric form, and renamed the
<code>article</code> as <code>product_name</code>. Finally, we deleted
the missing data via <code>filter()</code> and <code>article</code> via
<code>select()</code>. We created an <code>revenue</code> by
<code>unit_price</code> * <code>quantity</code>.
<p>
 
</p >
</div>
<div id="motivation" class="section level2">
<h2>Motivation</h2>
<p>It is 10:05 am in the morning, you sit in the lecture hall having
your earliest lecture of the day Data Science, empty-stomached. A cup of
coffee and a nicely warmed chocolate croissant or as French says ‘Pain
Au Chocolat’ is the only thing existing in your mind… You wonder why the
bakery items are so good and what you can do with it accompanied with
the ongoing endless talking of data science explained by your energetic
professor… Well, you jumped online and searched datasets for a French
bakery and here it happens…</p>
<p>Bread is so much a part of French culture that even the word for
“friend” comes from Latin cum pane (with bread) meaning the person with
whom you break bread. These everyday bakery items can still be something
of a mystery to people like you and me (I mean, who doesn’t like
carbs?)</p>
In this journey, we will take you around the analysis of a typical
French bakery and find out what’s the best-seller, how much they sell,
how is the sale distributed and so much more…
<p>
 
</p >
</div>
<div id="related-work" class="section level2">
<h2>Related work</h2>
<p>
 
</p >
</div>
<div id="initial-questions" class="section level2">
<h2>Initial questions</h2>
<p>
 
</p >
</div>
<div id="exploratory-analyses" class="section level2">
<h2>Exploratory analyses</h2>
<p>
 
</p >
</div>
<div id="forecast-modeling" class="section level2">
<h2>Forecast modeling</h2>
<p>
 
</p >
<p>We will be testing four forecast models and identify the best model
to help us predict the daily sale for this French bakery.</p>
<p>
 
</p >
<p>Sales forecast is important because it can be used as a daily
production reference and help the bakery to operate smoothly and reduce
wasting of resources, which in turn can reduce costs and increase
profit.</p>
<p>
 
</p >
<p>Time series forecasting involves using historical, time-stamped data
to make predictions of what might happen in the future.</p>
<p>
 
</p >
</div>
<div id="summary-of-packages" class="section level2">
<h2>Summary of packages</h2>
<p>tidyverse, forecast, astsa, MLmetrics, lubridate</p>
<pre class="r"><code># Load and clean dataset:

bakery_df = 
  read_csv(&quot;./Data/Bakery_sales.csv&quot;) %&gt;% 
  janitor::clean_names() %&gt;% 
  mutate(
    unit_price = str_replace(unit_price, &quot;€&quot;, &quot;&quot;),
    unit_price = str_replace(unit_price, &quot;,&quot;, &quot;.&quot;),
    unit_price = as.numeric(unit_price),
    year = year(date),
    month = month(date),
    hour = hour(time),
    product_name = article) %&gt;% 
  filter(product_name != &quot;.&quot;) %&gt;% 
  select(-article)</code></pre>
<p>In 2021, how many products were sold each day?</p>
<pre class="r"><code>sale_2021 = 
  bakery_df %&gt;% 
  filter(year == 2021) %&gt;% 
  select(date, year, month, hour, product_name, quantity, unit_price) %&gt;% 
  group_by(date) %&gt;% 
  summarize(
    total_sale = sum(quantity))

sale_2021 %&gt;% 
  head(10) %&gt;% 
  knitr::kable(digits = 2)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">date</th>
<th align="right">total_sale</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2021-01-02</td>
<td align="right">581</td>
</tr>
<tr class="even">
<td align="left">2021-01-03</td>
<td align="right">564</td>
</tr>
<tr class="odd">
<td align="left">2021-01-04</td>
<td align="right">315</td>
</tr>
<tr class="even">
<td align="left">2021-01-05</td>
<td align="right">309</td>
</tr>
<tr class="odd">
<td align="left">2021-01-07</td>
<td align="right">310</td>
</tr>
<tr class="even">
<td align="left">2021-01-08</td>
<td align="right">316</td>
</tr>
<tr class="odd">
<td align="left">2021-01-09</td>
<td align="right">394</td>
</tr>
<tr class="even">
<td align="left">2021-01-10</td>
<td align="right">473</td>
</tr>
<tr class="odd">
<td align="left">2021-01-11</td>
<td align="right">291</td>
</tr>
<tr class="even">
<td align="left">2021-01-12</td>
<td align="right">258</td>
</tr>
</tbody>
</table>
<p>The <code>sale_2021</code> dataset shows the number of products sold
each day in 2021. In 2021, the bakery opened for business for 339
days.</p>
<p>The line plot below shows the total number of products sold each day
in 2021.</p>
<pre class="r"><code>sale_2021 %&gt;% 
  ggplot(aes(x = date, y = total_sale)) +
  geom_line(aes(color = &quot;Orange&quot;)) +
  scale_x_date(date_labels = &quot;%b %Y&quot;, date_breaks  = &quot;1 month&quot;) +
  labs(
    x = &quot;Date&quot;,
    y = &quot;Number of products sold&quot;,
    title = &quot;Bakery&#39;s Daily Sales (2021)&quot;) +
  theme_minimal() +
  theme(legend.position = &quot;none&quot;) +
  theme(
    axis.text = element_text(size = 15),
    axis.title = element_text(size = 17, face = &quot;bold&quot;),
    plot.title = element_text(hjust = 0.4, size = 19, face = &quot;bold&quot;))</code></pre>
<p><img src="final_report_files/figure-html/2021%20daily%20sales%20line%20plot-1.png" width="90%" /></p>
<p>We will see this trend again as we verify the accuracy of different
forecast models in the next few sections.</p>
<p>
 
</p>
<div id="data-pre-processing" class="section level3">
<h3>Data Pre-processing</h3>
<p>We need to create a simple and clean dataframe derived from the
original dataset <code>bakery_df</code> that can be used by the forecast
models. This new dataframe only needs two columns:<br />
* <code>date</code> : date order in which the bakery opened for
business<br />
* <code>total_sale</code> : sum of products sold</p>
<p>The <code>sales_all</code> dataframe consists of 600 rows, in which
the dates begin with <em>January 2, 2021</em> and end with <em>September
30, 2022</em>.</p>
<pre class="r"><code>sales_all = 
  bakery_df %&gt;% 
  group_by(date) %&gt;% 
  summarize(
    total_sale = sum(quantity))</code></pre>
<p>Then, we need to create a <code>train</code> and a <code>test</code>
data frames so that we can test the accuracy of our forecast models. We
will be using all data prior to <em>September 1, 2022</em> as our
<code>train</code> dataset to predict the amount of products sold daily
for September, 2022. The remaining data from <em>September 1, 2022</em>
to <em>September 30, 2022</em> will be our <code>test</code>
dataset.</p>
<pre class="r"><code>train = 
  sales_all %&gt;% 
  filter(date &lt; &quot;2022-09-01&quot;)

test = 
  sales_all %&gt;% 
  filter(year(date) == 2022 &amp; month(date) == 9)</code></pre>
<p>
 
</p>
<div id="mean-absolute-percentage-error-mape" class="section level4">
<h4>Mean Absolute Percentage Error (MAPE)</h4>
<p>For model evaluation, we will be relying on the <strong><em>Mean
Absolute Percentage Error (MAPE)</em></strong> to measure the accuracy
of our predictions. <em>MAPE</em> is a numeric value which ranges
between 0 to 1.</p>
<p>The accuracy of the model can be calculated as <span
class="math inline">\((1 - MAPE) * 100%\)</span>. For example, an
<em>MAPE</em> value of 0.7 indicates the model has an accuracy of
30%.</p>
<p>We will report each model’s accuracy using inline R code.</p>
<p>
 
</p>
</div>
</div>
<div id="seasonal-naive-model" class="section level3">
<h3>Seasonal Naive Model</h3>
<p>First, we begin with the most basic forecast model - the
<strong>Seasonal Naive Model</strong>.</p>
<p>Naive forecasting is a simple and cost-effective method in which the
forecasts produced are equal to the last observed value. The seasonal
naive approach is used when the time series exhibits seasonality, in
which case, the forecasts are equivalent to the value from the last
season. Naive methods are typically used as a benchmark against which
more sophisticated forecasting techniques can be compared.</p>
<pre class="r"><code># Fit the model
seasonal_naive_model = snaive(train$total_sale, h = length(test$total_sale))

# Compute error of the model
SNM_error = MAPE(seasonal_naive_model$mean, test$total_sale) * 100</code></pre>
<p><strong>The accuracy of the <em>Seasonal Naive</em> model is
80.93%.</strong></p>
<p>The <em>Seasonal Naive</em> model will output a list of mean values,
and they are the predicted values of daily sales from September 1, 2022
to September 30, 2022. We need to extract the list of mean values from
the model and put them into the <code>test</code> dataframe so that we
can produce a time-series forecast plot.</p>
<pre class="r"><code>test_seasonal = 
  test %&gt;% 
  mutate(
    pred_sale = seasonal_naive_model$mean)</code></pre>
<p>Finally, we can plot a time-series forecasting graph to show the
results of our <em>Seasonal Naive</em> model.</p>
<pre class="r"><code>train %&gt;% 
  ggplot(aes(x = date, y = total_sale)) +
  geom_line(aes(color = &quot;Actual sale (Prior to 2022-09-01)&quot;)) +
  geom_line(data = test_seasonal, aes(x = date, y = total_sale, color = &quot;Actual sale (2022-09-01 to 2022-09-30)&quot;)) + 
  geom_line(data = test_seasonal, aes(x = date, y = pred_sale, color = &quot;Predicted sale (2022-09-01 to 2022-09-30)&quot;), size = 1.5) +
  scale_x_date(date_labels = &quot;%b %Y&quot;, date_breaks  = &quot;2 month&quot;) +
  labs(
    x = &quot;Date&quot;,
    y = &quot;Number of products sold&quot;,
    title = &quot;Seasonal Naive Forecast of Daily Sales for September (2022)&quot;) +
  theme_minimal() +
  theme(legend.position = &quot;bottom&quot;) +
  theme(
    axis.text = element_text(size = 15),
    axis.title = element_text(size = 17, face = &quot;bold&quot;),
    plot.title = element_text(hjust = 0.4, size = 19, face = &quot;bold&quot;),
    legend.text = element_text(size = 17),
    legend.title = element_text(size = 17))</code></pre>
<p><img src="final_report_files/figure-html/plot%20SNM%20prediction-1.png" width="90%" /></p>
<p>
 
</p>
<p>Comments: Although the <em>Seasonal Naive Model</em> gives high
accuracy, the prediction line is a horizontal straight line, which means
this model predicted that the amount of products sold is the same for
each day. Therefore, we think that the predictions from this model are
not the best.</p>
<p>
 
</p>
</div>
<div id="double-seasonal-holt-winters-dshw-model"
class="section level3">
<h3>Double-Seasonal Holt-Winters (DSHW) Model</h3>
<p>The <strong>Double-seasonal Holt-Winters</strong> method uses
additive trend and multiplicative seasonality, where there are two
seasonal components which are multiplied together. The length of the two
seasonalities must be multiples of one another (2 and 4, 4 and 12,
etc.). In our case, we will specify the length of the first seasonality
as 7 and the second as 14.</p>
<pre class="r"><code># Fit the model
double_seasonal_model = dshw(train$total_sale, period1 = 7, period2 = 14, h = length(test$total_sale))

# Compute the model&#39;s error
DSHW_error = MAPE(double_seasonal_model$mean, test$total_sale) * 100</code></pre>
<p><strong>The accuracy of the <em>Double-seasonal Holt-Winters</em>
model is 50.28%.</strong></p>
<p>The <em>DSHW</em> model will output a list of mean values, and they
are the predicted values of daily sales from September 1, 2022 to
September 30, 2022. We need to extract the list of mean values from the
model and put them into the <code>test</code> dataframe so that we can
produce a time-series forecast plot.</p>
<pre class="r"><code>test_double_seasonal = 
  test %&gt;% 
  mutate(
    pred_sale = double_seasonal_model$mean)</code></pre>
<p>Finally, we can plot a time-series forecasting graph to see the
results of our <em>DSHW</em> model.</p>
<pre class="r"><code>train %&gt;%
  filter(date &gt; &quot;2022-01-01&quot;) %&gt;% 
  ggplot(aes(x = date, y = total_sale)) +
  geom_line(aes(color = &quot;Actual sale (Prior to 2022-09-01)&quot;)) +
  geom_line(data = test_double_seasonal, aes(x = date, y = total_sale, color = &quot;Actual sale (2022-09-01 to 2022-09-30)&quot;)) + 
  geom_line(data = test_double_seasonal, aes(x = date, y = pred_sale, color = &quot;Predicted sale (2022-09-01 to 2022-09-30&quot;)) +
  scale_x_date(date_labels = &quot;%b %Y&quot;, date_breaks  = &quot;2 month&quot;) +
  labs(
    x = &quot;Date&quot;,
    y = &quot;Number of products sold&quot;,
    title = &quot;Double-Seasonal Holt-Winters Forecast of Daily Sales for September (2022)&quot;) +
  theme_minimal() +
  theme(legend.position = &quot;bottom&quot;) +
  theme(
    axis.text = element_text(size = 15),
    axis.title = element_text(size = 17, face = &quot;bold&quot;),
    plot.title = element_text(hjust = 0.4, size = 19, face = &quot;bold&quot;),
    legend.text = element_text(size = 17),
    legend.title = element_text(size = 17))</code></pre>
<p><img src="final_report_files/figure-html/DSHW%20prediction%20plot-1.png" width="90%" /></p>
<p>
 
</p>
<p>Comments: Although the <em>DSHW</em> model has a worse accuracy than
the basic model (<em>Seasonal Naive</em>), but visually it is better
than the basic model because it shows dynamic trend. This would make
more sense than the predictions given by the <em>Seasonal Naive</em>
model as we can see that it is no longer predicting that the daily sales
are the same for each day.</p>
<p>
 
</p>
</div>
<div id="tbats-model" class="section level3">
<h3>TBATS Model</h3>
<p><strong>TBATS</strong> is an acronym derived from the
<strong>Trigonometric seasonality, Box-Cox transformation, ARMA errors,
Trend, and Seasonal components</strong> of this approach. It takes its
roots from exponential smoothing methods and is capable of modeling time
series with multiple seasonalities.</p>
<pre class="r"><code># Train a TBATS model
TBATS_model = tbats(train$total_sale)

# Generate forecast with the model
tbats_df = forecast(TBATS_model, h = length(test$total_sale))

# Check the error for the model
TBATS_error = MAPE(tbats_df$mean, test$total_sale) * 100</code></pre>
<p><strong>The accuracy of the <em>TBATS</em> model is
57.93%.</strong></p>
<p>The <em>TBATS</em> model will output a list of mean values, and they
are the predicted values of daily sales from September 1, 2022 to
September 30, 2022. We need to extract the list of mean values from the
model and put them into the <code>test</code> dataframe so that we can
produce a time-series forecast plot.</p>
<pre class="r"><code>test_tbats = 
  test %&gt;% 
  mutate(
    pred_sale = tbats_df$mean)</code></pre>
<pre class="r"><code>train %&gt;% 
  filter(date &gt; &quot;2022-01-01&quot;) %&gt;% 
  ggplot(aes(x = date, y = total_sale)) +
  geom_line(aes(color = &quot;Actual sale (Prior to 2022-09-01)&quot;)) +
  geom_line(data = test_tbats, aes(x = date, y = total_sale, color = &quot;Actual sale (2022-09-01 to 2022-09-30)&quot;)) + 
  geom_line(data = test_tbats, aes(x = date, y = pred_sale, color = &quot;Predicted sale (2022-09-01 to 2022-09-30&quot;), size = 0.8) +
  scale_x_date(date_labels = &quot;%b %Y&quot;, date_breaks  = &quot;2 month&quot;) +
  labs(
    x = &quot;Date&quot;,
    y = &quot;Number of products sold&quot;,
    title = &quot;TBATS Forecast of Daily Sales for September (2022)&quot;) +
  theme_minimal() +
  theme(legend.position = &quot;bottom&quot;) +
  theme(
    axis.text = element_text(size = 15),
    axis.title = element_text(size = 17, face = &quot;bold&quot;),
    plot.title = element_text(hjust = 0.4, size = 19, face = &quot;bold&quot;),
    legend.text = element_text(size = 17),
    legend.title = element_text(size = 17))</code></pre>
<p><img src="final_report_files/figure-html/TBATS%20plot-1.png" width="90%" /></p>
<p>
 
</p>
<p>Comments: As we can see from the plot, the prediction line (blue)
demonstrates dynamic pattern as the <em>DSHW</em> model, but the
accuracy of the <em>TBATS</em> model is slightly better than the
<em>DSHW</em> model.</p>
<p>
 
</p>
</div>
<div id="neural-network-model" class="section level3">
<h3>Neural Network Model</h3>
<p>A neural network is a series of algorithms that identifies patterns
and relationships in data, similar to the way the brain operates.</p>
<p>The <code>forecast</code> library comes with the option of a
feed-forward neural network with a single hidden layer and lagged inputs
for univariate time series forecasting.</p>
<pre class="r"><code># Train a neural network model
nn_model = nnetar(train$total_sale)

# Generate forecast with the model
nn_forecast_df = forecast(nn_model, h = length(test$total_sale))

# Check the MAPE
NN_error = MAPE(nn_forecast_df$mean, test$total_sale) * 100</code></pre>
<p><strong>The accuracy of the <em>Neural Network</em> model is
68.75%.</strong></p>
<p>The <em>Neural Network</em> model will output a list of mean values,
and they are the predicted values of daily sales from September 1, 2022
to September 30, 2022. We need to extract the list of mean values from
the model and put them into the <code>test</code> dataframe so that we
can produce a time-series forecast plot.</p>
<pre class="r"><code>test_nn = 
  test %&gt;% 
  mutate(
    pred_sale = nn_forecast_df$mean)</code></pre>
<pre class="r"><code>train %&gt;% 
# To show the prediction line more clearly, we are only showing the trends of daily sales after May 1, 2022.
  filter(date &gt; &quot;2022-05-01&quot;) %&gt;% 
  ggplot(aes(x = date, y = total_sale)) +
  geom_line(aes(color = &quot;Actual sale (Prior to 2022-09-01)&quot;)) +
  geom_line(data = test_nn, aes(x = date, y = total_sale, color = &quot;Actual sale (2022-09-01 to 2022-09-30)&quot;), alpha = 0.8) + 
  geom_line(data = test_nn, aes(x = date, y = pred_sale, color = &quot;Predicted sale (2022-09-01 to 2022-09-30)&quot;), size = 0.7, alpha = 0.8) +
  scale_x_date(date_labels = &quot;%b %Y&quot;, date_breaks  = &quot;1 month&quot;) +
  labs(
    x = &quot;Date&quot;,
    y = &quot;Number of products sold&quot;,
    title = &quot;Neural Network Forecast of Daily Sales for September (2022)&quot;) +
  theme_minimal() +
  theme(legend.position = &quot;bottom&quot;) +
  theme(
    axis.text = element_text(size = 15),
    axis.title = element_text(size = 17, face = &quot;bold&quot;),
    plot.title = element_text(hjust = 0.4, size = 19, face = &quot;bold&quot;),
    legend.text = element_text(size = 17),
    legend.title = element_text(size = 17))</code></pre>
<p><img src="final_report_files/figure-html/NN%20plot-1.png" width="90%" /></p>
<p>
 
</p>
<p>Comments: As shown in the plot, the predicted trendline (blue) looks
similar to the actual trendline (red) and highly overlaps it. Although
the prediction accuracy is not 100%, but this <mark ><strong>Neural
Network</strong></mark> model gives us the highest accuracy among all
forecast models that has been tested.</p>
<p>
 
</p>
</div>
<div id="sales-forecast-for-oct---dec-2022" class="section level3">
<h3>Sales Forecast for Oct - Dec 2022</h3>
<p>As we have identified that the <mark ><strong>Neural
Network</strong></mark> model gives us the <strong>highest
accuracy</strong> (68.75%), we will use this model to predict the future
daily sales from October to December in 2022.</p>
<p>This time, we will use all the data from January 1, 2021 to September
30, 2022 to fit into the <em>Neural Network</em> forecasting model to
predict the daily sales of October - December in 2022.</p>
<pre class="r"><code># Train the model
nn_future = nnetar(sales_all$total_sale)

# Generate the forecast
nn_future_df = forecast(nn_future, h = 92)</code></pre>
<p>Since predicted values given by the model do not comes with dates, we
need to create a dataframe with specific range of date to combine with
the predicted values.</p>
<pre class="r"><code>dates = seq(as.Date(&#39;2022-10-01&#39;), as.Date(&#39;2022-12-31&#39;), by = &#39;days&#39;)

date_df =
  tibble(
    A = letters[sample(1:26, 92, TRUE)])

date_df = 
  tibble(
    date = rep(dates, length.out = nrow(date_df)))

date_df =
  date_df %&gt;% 
  mutate(
    pred_sale = nn_future_df$mean)</code></pre>
<p>Then, we can plot a graph to show the predicted daily sales of the
bakery from October to December in 2022.</p>
<pre class="r"><code>date_df %&gt;% 
  ggplot(aes(x = date)) +
  geom_line(aes(y = pred_sale, color = &quot;Red&quot;)) +
  scale_x_date(date_labels = &quot;%b %d&quot;, date_breaks  = &quot;10 day&quot;) +
  labs(
    x = &quot;Date (Month Day)&quot;,
    y = &quot;Number of products sold each day&quot;,
    title = &quot;Predicted Daily Sales from October to December (2022)&quot;) +
  theme_minimal() +
  theme(legend.position = &quot;none&quot;) +
  theme(
    axis.text = element_text(size = 15),
    axis.title = element_text(size = 17, face = &quot;bold&quot;),
    plot.title = element_text(hjust = 0.4, size = 19, face = &quot;bold&quot;),
    legend.text = element_text(size = 17),
    legend.title = element_text(size = 17))</code></pre>
<p><img src="final_report_files/figure-html/predicted%20future%20sales-1.png" width="90%" /></p>
<p>
 
</p >
</div>
</div>
<div id="descriptions-of-approaches" class="section level2">
<h2>Descriptions of approaches</h2>
<p>
 
</p >
<p>We will perform several statistical analysis in this bakery including
ANOVA to check the mean difference of peak sale months between 2021 and
2022, One-Sample t-test to check the mean price of baguette with average
price in the nation, simple linear regression to test the linear
relationship between quantity of sale and hours in the day, and finally
multiple linear regression.</p>
</div>
<div id="discussion-of-results" class="section level2">
<h2>Discussion of results</h2>
<p>
 
</p >
<div id="anova" class="section level3">
<h3>ANOVA</h3>
<pre class="r"><code># Data input and cleaning 
bakery_df =
  read_csv(&quot;./Data/Bakery_sales.csv&quot;) %&gt;% 
  janitor::clean_names() %&gt;% 
  mutate(
    unit_price = str_replace(unit_price, &quot;€&quot;, &quot;&quot;),
    unit_price = str_replace(unit_price, &quot;,&quot;, &quot;.&quot;),
    unit_price = as.numeric(unit_price),
    product_name = article, 
    rev = quantity * unit_price
    ) %&gt;% 
  filter(product_name != &quot;.&quot;) %&gt;% 
  select(-article)</code></pre>
<p>ANOVA tests whether there is a difference in means of the groups at
each level (each individual month) of the independent variable of peak
months (Jun - Sep).</p>
<p>One way anova test can test if the mean sales of peak months (Jun -
Sep) in 2021 is different from the mean sales of peak months (Jun - Sep)
in 2022.</p>
<p>Our data contains 7 variables and 234000 observations, and we can
assume the large sample size being normally distributed by central limit
theorem. (The central limit theorem (CLT) states that the distribution
of sample means approximates a normal distribution as the sample size
gets larger(n&gt;30), regardless of the population’s distribution.)</p>
<p>The null hypothesis is that there is no difference in the mean sales
of peak months in 2021 and 2022.<br />
The alternative hypothesis is that the means are different from one
another.</p>
<pre class="r"><code>anova_df =
  bakery_df %&gt;% 
  mutate(
    year = year(date),
    month = month(date)
    ) 
  

one_sales = 
  anova_df %&gt;% 
  filter((month == 6)|(month == 7)|(month == 8)|(month == 9)) %&gt;% 
  filter(year == 2021) %&gt;% 
  group_by(year, month) %&gt;% 
  summarize(one_sales = n()) %&gt;% 
  group_by(year, month) %&gt;% 
  mutate(ID = cur_group_id())
  
two_sales = 
  anova_df %&gt;% 
  filter((month == 6)|(month == 7)|(month == 8)|(month == 9)) %&gt;% 
  filter(year == 2022) %&gt;% 
  group_by(year, month) %&gt;% 
  summarize(two_sales = n()) %&gt;% 
  group_by(year, month) %&gt;% 
  mutate(ID = cur_group_id())
  
anova_test_df = 
  left_join(one_sales, two_sales, by = c(&quot;ID&quot;))


one.way &lt;- aov(one_sales ~ two_sales, data = anova_test_df) %&gt;% 
  broom::tidy() %&gt;% 
  knitr::kable(digits = 2) 

one.way</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">df</th>
<th align="right">sumsq</th>
<th align="right">meansq</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">two_sales</td>
<td align="right">1</td>
<td align="right">74405982.9</td>
<td align="right">74405982.9</td>
<td align="right">196.63</td>
<td align="right">0.01</td>
</tr>
<tr class="even">
<td align="left">Residuals</td>
<td align="right">2</td>
<td align="right">756817.1</td>
<td align="right">378408.5</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
<p>The ANOVA test p-value is 0.01 which is less than alpha level of
0.05, so we reject the null hypothesis and conclude that the mean sales
of peak months in 2021 is statistically significantly different from the
mean sales of peak months in 2022. According to the Exploratory Analysis
graphs, 2022 has increased the overall sales compared to 2021. This
might due to the reasons of COVID-19 pandemic during 2021 and a better
recovery with less restricted rules in 2022, which makes a significant
difference in same period of the two years.</p>
<p>
 
</p >
</div>
<div id="one-sample-t-test" class="section level3">
<h3>One Sample T-test</h3>
<p>We are interested in testing if the mean price of
<code>BAGUETTE</code> in this bakery is significantly different from the
average price for a baguette in Paris, which is 1.07 euros.</p>
<p>
 
</p>
<p><img src="images/baguette.gif" style="width:100%"></p>
<p>Null hypothesis: The mean price of baguette in this bakery is the
same as the average price of baguette in Paris.</p>
<p>Alternative hypothesis: The mean price of baguette in this bakery is
different from the average price of baguette in Paris.</p>
<p>Our population follows a Poisson distribution as shown below, and we
can assume the large sample size being normally distributed by central
limit theorem.</p>
<pre class="r"><code>bakery_df %&gt;% 
  filter(product_name == &quot;TRADITIONAL BAGUETTE&quot;) %&gt;% 
  group_by(date) %&gt;% 
  summarize(total_sale = sum(quantity)) %&gt;% 
  ggplot(aes(x = total_sale)) +
  geom_histogram() +
  labs(
    x = &quot;Total sale quantity per day&quot;, 
    y = &quot;Count&quot;,
    title = &quot;Distribution of sale quantity&quot;) +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14, face = &quot;bold&quot;),
    plot.title = element_text(hjust = 0.4, face = &quot;bold&quot;))</code></pre>
<p><img src="final_report_files/figure-html/unnamed-chunk-2-1.png" width="90%" /></p>
<pre class="r"><code>baguette_onet = 
  bakery_df %&gt;% 
  filter(product_name == &quot;BAGUETTE&quot;) %&gt;%
  select(unit_price)

baguette_t_results = 
  t.test(baguette_onet, mu = 1.07 , alternative = &quot;two.sided&quot;) %&gt;% 
  broom::tidy() 

baguette_t_results %&gt;% 
  knitr::kable(digits = 4)</code></pre>
<table>
<colgroup>
<col width="10%" />
<col width="11%" />
<col width="9%" />
<col width="11%" />
<col width="10%" />
<col width="11%" />
<col width="20%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">estimate</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
<th align="right">parameter</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
<th align="left">method</th>
<th align="left">alternative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.9291</td>
<td align="right">-442.2184</td>
<td align="right">0</td>
<td align="right">15291</td>
<td align="right">0.9285</td>
<td align="right">0.9297</td>
<td align="left">One Sample t-test</td>
<td align="left">two.sided</td>
</tr>
</tbody>
</table>
<p>The p-value is much smaller than the alpha (0.05), so we would reject
the null hypothesis. At 5% level of significance, we have sufficient
evidence to conclude that the mean price of baguette in this bakery is
significantly different from the average price of baguette in Paris.</p>
<p>
 
</p >
</div>
<div id="traditional-baguette-one-sided" class="section level3">
<h3>Traditional Baguette (One-sided)</h3>
<p>We noticed that the price of traditional baguette in this bakery is
higher than the average price of traditional baguette in France. The
price of the traditional French loaf is around 0.90 Euros in bakeries.
Therefore, we would like to conduct a one-sided T-test to see if the
price difference is significant.</p>
<p>Null hypothesis: The mean price of traditional baguette in this
bakery is the same as the average price of traditional baguette in
France.</p>
<p>Alternative hypothesis: The mean price of traditional baguette in
this bakery is higher than the average price of traditional baguette in
France.</p>
<pre class="r"><code>bakery_df %&gt;% 
  filter(product_name == &quot;TRADITIONAL BAGUETTE&quot;) %&gt;% 
  count(unit_price) %&gt;% 
   knitr::kable(digits = 4)</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">unit_price</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1.20</td>
<td align="right">39426</td>
</tr>
<tr class="even">
<td align="right">1.25</td>
<td align="right">13059</td>
</tr>
<tr class="odd">
<td align="right">1.30</td>
<td align="right">15204</td>
</tr>
</tbody>
</table>
<pre class="r"><code>trad_baguette_onet = 
  bakery_df %&gt;% 
  filter(product_name == &quot;TRADITIONAL BAGUETTE&quot;) %&gt;%
  select(unit_price)

trad_baguette_t_results = 
  t.test(trad_baguette_onet, mu = 0.90, alternative = &quot;greater&quot;) %&gt;% 
  broom::tidy() 

trad_baguette_t_results %&gt;% 
   knitr::kable(digits = 4)</code></pre>
<table>
<colgroup>
<col width="10%" />
<col width="11%" />
<col width="9%" />
<col width="11%" />
<col width="10%" />
<col width="11%" />
<col width="20%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">estimate</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
<th align="right">parameter</th>
<th align="right">conf.low</th>
<th align="right">conf.high</th>
<th align="left">method</th>
<th align="left">alternative</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1.2321</td>
<td align="right">2097.119</td>
<td align="right">0</td>
<td align="right">67688</td>
<td align="right">1.2318</td>
<td align="right">Inf</td>
<td align="left">One Sample t-test</td>
<td align="left">greater</td>
</tr>
</tbody>
</table>
<p>The p-value is much smaller than the alpha (0.05), so we would reject
the null hypothesis. At 5% level of significance, we have sufficient
evidence to conclude that the mean price of traditional baguette in this
bakery is significantly higher than the average price of baguette in
Paris.</p>
<p>
 
</p >
</div>
<div id="simple-linear-regression" class="section level3">
<h3>Simple Linear Regression</h3>
<p>We conduct a simple linear regression for <code>CROISSANT</code>’s
sale counts and when it’s being sold (hour of the day) and test the
model using <code>Cross Validation</code>.</p>
<p><img src="images/croissant.gif" style="width:100%"></p>
<p>The plot below shows the average amount of products sold in each hour
during the business hour.</p>
<pre class="r"><code>bakery_df = 
  bakery_df %&gt;% 
  mutate(
    Hour = hour(time),
    Month = month(date))

bakery_df %&gt;% 
  group_by(Hour) %&gt;% 
  count() %&gt;%
  mutate(
    average_count = n / 600) %&gt;% 
  ggplot(aes(x = Hour, y = average_count)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = seq(7, 20), limit = c(7, 20)) +
  scale_y_continuous(limit = c(0, 80)) +
  labs(
    title = &quot;Average amount of products sold in every hour per day&quot;,
    x = &quot;Hour (24-hour format)&quot;,
    y = &quot;Number of products sold&quot;) +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14, face = &quot;bold&quot;),
    plot.title = element_text(hjust = 0.4, face = &quot;bold&quot;))</code></pre>
<p><img src="final_report_files/figure-html/unnamed-chunk-4-1.png" width="90%" /></p>
<p>From the graph above, it seems like there is a linear trend from 7 AM
to 11 AM. Hence, we should take a look at the morning hours with a
monotonic function from 7 AM to 11 AM.</p>
<pre class="r"><code>bakery_df %&gt;% 
  mutate(year = year(date)) %&gt;% 
  filter(year == 2021) %&gt;% 
  group_by(Hour) %&gt;% 
  summarize(
    n_sold = sum(quantity) / 365) %&gt;% 
  ggplot(aes(x = Hour, y = n_sold)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = seq(7, 11), limit = c(7, 11)) +
  scale_y_continuous(limit = c(0, 120)) +
  labs(
    title = &quot;Average amount of products sold from 7am - 11am&quot;,
    x = &quot;Hour (24-hour format)&quot;,
    y = &quot;Number of products sold&quot;) +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14, face = &quot;bold&quot;),
    plot.title = element_text(hjust = 0.4, face = &quot;bold&quot;))</code></pre>
<p><img src="final_report_files/figure-html/unnamed-chunk-5-1.png" width="90%" /></p>
<p>It looks like a monotonic linear relationship that we can take a
further look at using simple linear regression model.</p>
<pre class="r"><code>slr_df = 
  bakery_df  %&gt;% 
  mutate(
    hour_cp = (Hour &gt; 8) * (Hour - 8))

slr_reg = lm(quantity ~ Hour, slr_df)

slr_reg %&gt;% 
  broom::tidy() %&gt;% 
  knitr::kable(digits = 2) </code></pre>
<table>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">1.99</td>
<td align="right">0.01</td>
<td align="right">182.09</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">Hour</td>
<td align="right">-0.04</td>
<td align="right">0.00</td>
<td align="right">-42.57</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>The model is Sale count = 1.99 - 0.04 * Hour</p>
<p>
 
</p >
<div id="cross-validation" class="section level4">
<h4>Cross validation</h4>
<pre class="r"><code># created 3 models: linear, piecewise, and smooth models 
linear_mod = lm(quantity ~ Hour, slr_df)
pwl_mod    = lm(quantity ~ Hour + hour_cp, data = slr_df)
smooth_mod = gam(quantity ~ s(Hour), data = slr_df)</code></pre>
<pre class="r"><code>slr_df %&gt;% 
  gather_predictions(linear_mod, pwl_mod, smooth_mod) %&gt;% 
  mutate(model = fct_inorder(model)) %&gt;% 
  ggplot(aes(x = Hour, y = quantity)) + 
  geom_point(alpha = .5, size = 0.05) +
  geom_line(aes(y = pred), color = &quot;red&quot;) +
  ylim(1, 2) +
  facet_grid(~model)</code></pre>
<p><img src="final_report_files/figure-html/unnamed-chunk-8-1.png" width="90%" /></p>
<p>The three models with original scales are very similar. Therefore,
when we visualize the three models, we change the y-axis scale to 0-3 as
a zoom-in function in order to see the nuance differences between each
model.</p>
<p>Re-sample the dataset by <code>crossv_mc</code> and let’s see the
rmse of each model and make a table</p>
<pre class="r"><code># created a train model and test model; check rmse 
set.seed(2022)
cv_df =
  crossv_mc(slr_df, 100) %&gt;% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %&gt;% 
  mutate(
    linear_mod  = map(train, ~lm(quantity ~ Hour, data = .x)),
    pwl_mod     = map(train, ~lm(quantity ~ Hour + hour_cp, data = .x)),
    smooth_mod  = map(train, ~gam(quantity ~ s(Hour), data = as_tibble(.x)))) %&gt;% 
  mutate(
    rmse_linear = map2_dbl(linear_mod, test, ~rmse(model = .x, data = .y)),
    rmse_pwl    = map2_dbl(pwl_mod, test, ~rmse(model = .x, data = .y)),
    rmse_smooth = map2_dbl(smooth_mod, test, ~rmse(model = .x, data = .y))) 

  cv_df %&gt;% 
  select(rmse_linear, rmse_pwl, rmse_smooth) %&gt;% 
  pivot_longer(
    everything(),
    names_to = &quot;model&quot;, 
    values_to = &quot;rmse&quot;,
    names_prefix = &quot;rmse_&quot;) %&gt;% 
  group_by(model) %&gt;% 
  summarize(mean(rmse)) %&gt;% 
  mutate(mean_rmse = `mean(rmse)`) %&gt;% 
  select(-`mean(rmse)`) %&gt;% 
  knitr::kable(digits = 4)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">model</th>
<th align="right">mean_rmse</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">linear</td>
<td align="right">1.2719</td>
</tr>
<tr class="even">
<td align="left">pwl</td>
<td align="right">1.2715</td>
</tr>
<tr class="odd">
<td align="left">smooth</td>
<td align="right">1.2688</td>
</tr>
</tbody>
</table>
<p>Then plot the rmse graph</p>
<pre class="r"><code>cv_df %&gt;% 
  select(starts_with(&quot;rmse&quot;)) %&gt;% 
  pivot_longer(
    everything(),
    names_to = &quot;model&quot;, 
    values_to = &quot;rmse&quot;,
    names_prefix = &quot;rmse_&quot;) %&gt;% 
  mutate(model = fct_inorder(model)) %&gt;% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()</code></pre>
<p><img src="final_report_files/figure-html/unnamed-chunk-10-1.png" width="90%" />
From the visualization graphs of three rmse models, it is hard to
determine the slightly change of each model, but from our mean rmse
table we conclude that the smooth model is the best out of the three
with the least mean rmse (1.2688).</p>
<p>Based on the results, there is a slightly improvement using smooth
model as it has the lowest rmse, we can conclude that the smooth model
is to be accounted for this relationship in the product of
croissant.</p>
<p>
 
</p >
</div>
</div>
<div id="multiple-linear-regression" class="section level3">
<h3>Multiple Linear Regression</h3>
<p>We are interested in testing the relationship between the revenue
(outcome variable) and 2 main predictors, which are unit price of a
product and its quantity being sold. Considering that the sales of
bakery varies by month, we included <code>month</code> in our model as a
confounder to be controlled.</p>
<p>
 
</p>
<p>Multivariable linear regression model</p>
<pre class="r"><code>baguette_df = 
  bakery_df %&gt;% 
  filter(str_detect(product_name, &quot;BAGUETTE&quot;)) %&gt;% 
  mutate(
    month = month(date)
  )
baguette_reg = lm(rev ~ unit_price + quantity + month, baguette_df)


baguette_reg %&gt;% 
  broom::tidy() %&gt;% 
  knitr::kable(digits = 4)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">-1.4321</td>
<td align="right">0.0038</td>
<td align="right">-374.6061</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">unit_price</td>
<td align="right">1.2071</td>
<td align="right">0.0031</td>
<td align="right">393.5209</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">quantity</td>
<td align="right">1.1881</td>
<td align="right">0.0005</td>
<td align="right">2603.5416</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">month</td>
<td align="right">0.0012</td>
<td align="right">0.0002</td>
<td align="right">6.1995</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>Examine assumptions for the chosen Linear Regression model</p>
<pre class="r"><code>par(mfrow = c(2, 2))
plot(baguette_reg)</code></pre>
<p><img src="final_report_files/figure-html/unnamed-chunk-12-1.png" width="90%" /></p>
<p>According to the assumption check graph, the normal qq plot is
approximately closed to the predicted line with residuals on both sides,
but the residual plots might violate some of the linear regression
assumptions (homoscedasticity).</p>
<p>The tentative model for multiple linear regression of baguette’s
revenue is<br />
Revenue = -1.43 + 1.21 * unit_price + 1.19 * quantity + 0.001 *
month</p>
<p>We might not consider doing MLR for the sake of this research due to
the unmet assumptions.</p>
<p>
 
</p >
</div>
</div>
<div id="strengths-and-limitations" class="section level2">
<h2>Strengths and Limitations</h2>
<p>
 
</p >
</div>
<div id="finding-summary-and-expectation" class="section level2">
<h2>Finding, Summary, and Expectation</h2>
<p>
 
</p >
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
